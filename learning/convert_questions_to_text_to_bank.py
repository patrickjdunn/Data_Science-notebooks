# convert_questions_from_text.py
"""
convert_questions_from_text.py

Converter script to generate structured question sets from a raw pasted text file.

Usage:
  cd learning
  python convert_questions_from_text.py input.txt output_questions_generated.py

What it does:
- Parses sections like:
    "Top 10 Questions People with X Ask Their Doctor"
    "Question 1: “...?”"
    "• Listener ..."
    "Action Step: ..."
    "Why: ..."
- Emits a Python module with RAW_QUESTION_SETS entries that you can paste/merge into questions.py,
  OR import directly as an additional module.

This keeps questions.py manageable and prevents syntax errors from manual copy/paste.
"""

from __future__ import annotations

import re
import sys
from typing import Dict, Any, List, Tuple


PERSONAS = ["Listener", "Motivator", "Director", "Expert"]


def normalize_category(title: str) -> str:
    t = title.lower()
    if "high blood pressure" in t or "hypertension" in t:
        return "HTN"
    if "cardio" in t and "kidney" in t and "metabolic" in t:
        return "CKM"
    if "coronary" in t or "cad" in t:
        return "CAD"
    if "heart failure" in t:
        return "HF"
    if "atrial fibrillation" in t or "afib" in t:
        return "AFIB"
    if "stroke" in t:
        return "STROKE"
    if "diabetes" in t:
        return "DM"
    return "GEN"


def parse_text(text: str) -> List[Tuple[str, List[Dict[str, Any]]]]:
    # Split into condition blocks by "Top 10 Questions"
    # Works best if your pasted text includes those headers.
    blocks = re.split(r"\n\s*\n", text)
    joined = "\n".join(blocks)

    # Find section headers
    header_pat = re.compile(r"(Top\s+10\s+Questions[^\n]+)", re.IGNORECASE)
    headers = [(m.start(), m.group(1).strip()) for m in header_pat.finditer(joined)]
    if not headers:
        return [("GEN", parse_questions_block(joined))]

    outputs: List[Tuple[str, List[Dict[str, Any]]]] = []
    for i, (pos, header) in enumerate(headers):
        end = headers[i + 1][0] if i + 1 < len(headers) else len(joined)
        section_text = joined[pos:end]
        cat = normalize_category(header)
        items = parse_questions_block(section_text)
        if items:
            outputs.append((cat, items))
    return outputs


def parse_questions_block(section_text: str) -> List[Dict[str, Any]]:
    # Capture question boundaries
    q_pat = re.compile(r"Question\s+(\d+)\s*:\s*[“\"](.+?)[”\"]\s*", re.IGNORECASE)
    matches = list(q_pat.finditer(section_text))
    items: List[Dict[str, Any]] = []

    for idx, m in enumerate(matches):
        q_text = m.group(2).strip()
        start = m.end()
        end = matches[idx + 1].start() if idx + 1 < len(matches) else len(section_text)
        chunk = section_text[start:end]

        responses = {}
        for persona in PERSONAS:
            # Persona line often: "• Listener  “... ”"
            p_pat = re.compile(rf"{persona}\s*[–\-]?\s*[“\"](.+?)[”\"]", re.IGNORECASE)
            pm = p_pat.search(chunk)
            if pm:
                responses[persona] = pm.group(1).strip()

        # Action Step / Why
        action = ""
        why = ""
        am = re.search(r"Action Step\s*:\s*(.+)", chunk, re.IGNORECASE)
        if am:
            action = am.group(1).strip()
        wm = re.search(r"Why\s*:\s*(.+)", chunk, re.IGNORECASE)
        if wm:
            why = wm.group(1).strip()

        items.append({
            "question": q_text,
            "responses": responses,
            "action_step": action or "Choose one small next step you can do today.",
            "why": why or "Small steps build momentum and confidence.",
            # Tags can be added later (or heuristically)
            "signatures_tags": {"behavioral_core": ["GEN"], "condition_modifiers": [], "engagement_drivers": []},
            "security_rule_codes": [],
            "action_plan_codes": [],
            "sources": [],
        })

    return items


def emit_python_module(data: List[Tuple[str, List[Dict[str, Any]]]]) -> str:
    lines = []
    lines.append("# Auto-generated by convert_questions_from_text.py")
    lines.append("from typing import Any, Dict, List, Tuple")
    lines.append("")
    lines.append("RAW_QUESTION_SETS: List[Tuple[str, List[Dict[str, Any]]]] = []")
    lines.append("")

    for cat, items in data:
        lines.append(f"{cat}_ITEMS: List[Dict[str, Any]] = [")
        for it in items:
            lines.append("    {")
            lines.append(f"        'question': {it['question']!r},")
            lines.append(f"        'responses': {it['responses']!r},")
            lines.append(f"        'action_step': {it['action_step']!r},")
            lines.append(f"        'why': {it['why']!r},")
            lines.append(f"        'signatures_tags': {it['signatures_tags']!r},")
            lines.append(f"        'security_rule_codes': {it['security_rule_codes']!r},")
            lines.append(f"        'action_plan_codes': {it['action_plan_codes']!r},")
            lines.append(f"        'sources': {it['sources']!r},")
            lines.append("    },")
        lines.append("]")
        lines.append(f"RAW_QUESTION_SETS.append(('{cat}', {cat}_ITEMS))")
        lines.append("")

    return "\n".join(lines)


def main() -> None:
    if len(sys.argv) < 3:
        print("Usage: python convert_questions_from_text.py input.txt output_questions_generated.py")
        sys.exit(1)

    in_path = sys.argv[1]
    out_path = sys.argv[2]

    with open(in_path, "r", encoding="utf-8") as f:
        text = f.read()

    data = parse_text(text)
    py = emit_python_module(data)

    with open(out_path, "w", encoding="utf-8") as f:
        f.write(py)

    print(f"✅ Wrote: {out_path}")
    print("Next: import that module and merge RAW_QUESTION_SETS into questions.py.")


if __name__ == "__main__":
    main()

